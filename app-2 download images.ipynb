{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ae4195-227f-43a8-833a-1d7eab159dff",
   "metadata": {},
   "source": [
    "<a id = \"1\"></a><p style = \"font-size : 40px; color :#E7E8D1 ; font-family : 'Comic Sans MS'; text-align : center; background-color : #B85042; border-radius: 5px 5px;\"><strong>SECTION 2 - DOWNLOAD DATASET</strong></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ef2ff-e26d-408d-b33c-c8353bfaa8d6",
   "metadata": {},
   "source": [
    "<a id = \"1\"></a><p style = \"font-size : 40px; color :#E7E8D1 ; font-family : 'Comic Sans MS'; text-align : center; background-color : #B85042; border-radius: 5px 5px;\"><strong>1. LIBRARIES</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c38f9d-b240-48b0-80c0-f93b55517afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from selenium.webdriver.common.by import By\n",
    "from seleniumbase import Driver\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import sys\n",
    "import warnings\n",
    "from PIL import Image\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b514f4-8ae9-41ae-b4d2-0863d825f048",
   "metadata": {},
   "source": [
    "<a id = \"1\"></a><p style = \"font-size : 40px; color :#E7E8D1 ; font-family : 'Comic Sans MS'; text-align : center; background-color : #B85042; border-radius: 5px 5px;\"><strong>2. DOWNLOADING IMAGES USING MULTITHREADING</strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b97c9f-9ad2-4ebf-9500-e7d8424168ff",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82d9efe-256c-4ddf-a1e0-171dabab6920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df name  : 2_dataset\n",
      "Df length: 37\n"
     ]
    }
   ],
   "source": [
    "# Get Df from section-1 to download images\n",
    "from config import final_file_path, df_name, project_root\n",
    "df = pd.read_excel(final_file_path)\n",
    "print(f'Df name  : {df_name}')\n",
    "print(f'Df length: {len(df)}')\n",
    "\n",
    "# Create a Download Folder for Images\n",
    "downloaded_images = f\"{project_root}/downloaded_images/\" # commonly used folder path in the project\n",
    "os.makedirs(downloaded_images, exist_ok=True)\n",
    "\n",
    "# Lists and Configuration\n",
    "ok_images = list()\n",
    "not_ok_images = list()\n",
    "white_images = list()\n",
    "list_id_not_ok = []\n",
    "df[\"path\"] = \"\"\n",
    "not_downloaded_for_selenium = list()\n",
    "img_url_base = \"https://cdn.eksisozluk.com/\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Referer\": \"https://eksisozluk.com/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25e5ec-4b52-4ddf-817a-c936cb3c1595",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f76c45-6fb0-4a51-9da8-62648a9237b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 100%|██████████████████████████████████████████████████████████████| 37/37 [00:02<00:00, 14.33it/s]\n"
     ]
    }
   ],
   "source": [
    "def download_image(i):\n",
    "    img_url = df['img_url'][i]\n",
    "    img_index = df['img_index'][i]\n",
    "    entry_id = df['entry_id'][i]\n",
    "    \n",
    "    response = requests.get(img_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:  # 1- If 200: Download\n",
    "        img_path = os.path.join(downloaded_images, f\"img_{img_index}.jpg\")\n",
    "        with open(img_path, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "            \n",
    "    elif response.status_code == 404:  # 2- If 404: Create edit date URL and try downloading again\n",
    "        status_code = response.status_code\n",
    "        img_url_date = df['entry_edit_date'][i]\n",
    "        url_id = img_url.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        if pd.notna(img_url_date):\n",
    "            img_url_date = str(img_url_date)\n",
    "            date_object = datetime.strptime(img_url_date, \"%d.%m.%Y %H:%M\")\n",
    "            entry_day = str(date_object.day)\n",
    "            entry_month = str(date_object.month)\n",
    "            entry_year = str(date_object.year)\n",
    "            img_url = img_url_base + entry_year + '/' + entry_month + '/' + entry_day + '/' + url_id[0] + '/' + url_id + '.jpg'\n",
    "            response = requests.get(img_url, headers=headers)\n",
    "            \n",
    "            if response.status_code != 200:  # 3- If not 200: Try with PNG\n",
    "                img_url = img_url_base + entry_year + '/' + entry_month + '/' + entry_day + '/' + url_id[0] + '/' + url_id + '.png'\n",
    "                response = requests.get(img_url, headers=headers)\n",
    "                \n",
    "                if response.status_code != 200:  # 4- If not 200: Try edit date URL with one day earlier\n",
    "                    date_object -= timedelta(days=1)\n",
    "                    entry_year = date_object.strftime(\"%Y\")\n",
    "                    entry_month = str(int(date_object.strftime(\"%m\")))  # Not starting with 0\n",
    "                    entry_day = str(int(date_object.strftime(\"%d\")))    # Not starting with 0\n",
    "                    img_url = f\"{img_url_base}{entry_year}/{entry_month}/{entry_day}/{url_id[0]}/{url_id}.jpg\"\n",
    "                    response = requests.get(img_url, headers=headers)\n",
    "                    if response.status_code != 200: # 5- If not 200: Try one-day-earlier edit date URL with PNG\n",
    "                        img_url = img_url_base + entry_year + '/' + entry_month + '/' + entry_day + '/' + url_id[0] + '/' + url_id + '.png'\n",
    "                        response = requests.get(img_url, headers=headers)\n",
    "                        \n",
    "        else:\n",
    "            img_url = img_url.replace('jpg','png')\n",
    "            response = requests.get(img_url, headers=headers)\n",
    "            \n",
    "        if response.status_code == 200:  # 6- If 200: Download\n",
    "            img_path = os.path.join(downloaded_images, f\"img_{img_index}.jpg\")\n",
    "            #ok_images.append(img_index)\n",
    "            with open(img_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "                \n",
    "    else:\n",
    "        print(f'response.status_code is {response.status_code} for img_index={img_index}')\n",
    "        \n",
    "    # Add status_code to xlsx file\n",
    "    df.at[img_index-1, \"response_status_code\"] = response.status_code\n",
    "    \n",
    "    # Add img_index by looking statuscode\n",
    "    if response.status_code != 200:\n",
    "        not_downloaded_for_selenium.append(img_index)\n",
    "    else:\n",
    "        ok_images.append(img_index)\n",
    "        \n",
    "    # Write img_path to df\n",
    "    img_path = os.path.join(downloaded_images, f\"img_{img_index}.jpg\")\n",
    "    filename = img_path.split(\"\\\\\")[-1]\n",
    "    df.loc[i, \"path\"] = filename\n",
    "    if response.status_code == 200:\n",
    "        filename = img_path.split(\"\\\\\")[-1]\n",
    "        \n",
    "# Multithreading | Set up a ThreadPoolExecutor to download images concurrently\n",
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "    futures = [executor.submit(download_image, i) for i in range(0, len(df))]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Downloading images\"):\n",
    "        future.result()  # Waiting for all tasks to complete\n",
    "\n",
    "# Save final df & 404 df\n",
    "df.to_excel(f\"{df_name}_without_selenium_status_{len(df)}.xlsx\", index=False)\n",
    "dataset_without_selenium_404 = df[df[\"response_status_code\"] != 200]\n",
    "dataset_without_selenium_404.to_excel(f\"3_dataset_status_404.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac6541-822d-4484-b33e-889e2ae485ce",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97de5bed-856e-46a7-b9b1-1edae9433506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---All operations finished. Final file saved---\n",
      "Final file name: 2_dataset_without_selenium_status_37.xlsx\n",
      "Final Result:\n",
      "1) df lenght: 37\n",
      "2) ok_images lenght: 37\n",
      "3) not_ok_images lenght: 0\n",
      "4) not_downloaded_for_selenium lenght: 0\n",
      "5) not_downloaded_for_selenium indexes: []\n"
     ]
    }
   ],
   "source": [
    "# Final result\n",
    "print(\"\\n---All operations finished. Final file saved---\")\n",
    "print(f\"Final file name: {df_name}_without_selenium_status_{len(df)}.xlsx\")\n",
    "print(f'Final Result:')\n",
    "print(f'1) df lenght: {len(df)}')\n",
    "print(f'2) ok_images lenght: {len(ok_images)}')\n",
    "print(f'3) not_ok_images lenght: {len(not_ok_images)}')\n",
    "not_downloaded_for_selenium.sort()\n",
    "print(f'4) not_downloaded_for_selenium lenght: {len(not_downloaded_for_selenium)}')\n",
    "print(f'5) not_downloaded_for_selenium indexes: {[int(index) for index in not_downloaded_for_selenium]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62072b5-8f6a-4b90-b657-f25af5549eec",
   "metadata": {},
   "source": [
    "<a id = \"1\"></a><p style = \"font-size : 40px; color :#E7E8D1 ; font-family : 'Comic Sans MS'; text-align : center; background-color : #B85042; border-radius: 5px 5px;\"><strong>2. DOWNLOADING IMAGES USING SELENIUM</strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed166c3-9f94-466e-a0cd-ec08765db350",
   "metadata": {},
   "source": [
    "# Create Img List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c3ad76-f226-48aa-ba30-e51e07be1bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of missing images: 0\n",
      "Missing img_index values saved to 'C:\\Users\\soner.kar\\Desktop\\My Projects\\SözlükLens\\4_dataset_missing_images.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Identify the images to check with Selenium\n",
    "\n",
    "# 1- Read all .jpg files in the folder\n",
    "all_files = os.listdir(downloaded_images)\n",
    "jpg_files = [f for f in all_files if f.endswith('.jpg')]\n",
    "\n",
    "# 2- Extract existing file numbers\n",
    "existing_numbers = set()\n",
    "for filename in jpg_files:\n",
    "    try:\n",
    "        number_part = int(filename.replace(\"img_\", \"\").replace(\".jpg\", \"\"))\n",
    "        existing_numbers.add(number_part)\n",
    "    except ValueError:\n",
    "        pass  # ignore files with incorrect names\n",
    "\n",
    "# 3- All expected numbers from 1 to the last index\n",
    "full_set = set(range(1, len(df)+1))  # 69431 dahil olsun diye 69432 yazdım\n",
    "\n",
    "# 4- Missing files\n",
    "missing_numbers = full_set - existing_numbers\n",
    "print(f\"Total number of missing images: {len(missing_numbers)}\")\n",
    "\n",
    "# 5- Read the Excel file\n",
    "df = pd.read_excel(final_file_path)\n",
    "\n",
    "# 6- Keep only the img_index values of the missing files\n",
    "df_filtered = df[df['img_index'].isin(missing_numbers)]\n",
    "\n",
    "# 7- Save as a new file\n",
    "from config import project_root\n",
    "path_output = os.path.join(project_root, '4_dataset_missing_images.xlsx')\n",
    "df_filtered.to_excel(path_output, index=False)\n",
    "\n",
    "print(f\"Missing img_index values saved to '{path_output}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de5092-39d2-4de8-b250-f1ce7544f12c",
   "metadata": {},
   "source": [
    "# Run Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b93341c-7222-460b-89a4-6bfce3644ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images to retry with Selenium: 0\n",
      "Selenium will run now...\n",
      "Selenium has finished running.\n",
      "\n",
      "-Result-\n",
      "Lenght of Ok Images:  0\n",
      "Lenght of Not Ok Images:  0\n"
     ]
    }
   ],
   "source": [
    "downloaded_images_selenium = f\"{project_root}/downloaded_images_selenium/\"\n",
    "os.makedirs(downloaded_images_selenium, exist_ok=True)\n",
    "\n",
    "df_missings = pd.read_excel(path_output)\n",
    "not_downloaded_for_selenium  = df_missings['img_index'].tolist()\n",
    "####### df = pd.read_excel(r\"C:\\Users\\soner.kar\\Desktop\\My Projects\\2- Ekşi Sözlük Sözlük Yazarlarının Çektiği Fotoğraflar\\dataset_69431_updated.xlsx\")\n",
    "df = df_missings\n",
    "\n",
    "not_ok_images_selenium = list()\n",
    "ok_images_selenium = list()\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Referer\": \"https://eksisozluk.com/\",\n",
    "}\n",
    "\n",
    "print(f\"Number of images to retry with Selenium: {len(not_downloaded_for_selenium)}\")\n",
    "#print('Images index to retry with Selenium: ', not_downloaded_for_selenium)\n",
    "# Go to Ekşi Sözlük login page\n",
    "img_url_base = \"https://cdn.eksisozluk.com/\"\n",
    "# Start Selenium WebDriver\n",
    "print('Selenium will run now...')\n",
    "driver = Driver(uc=True)\n",
    "driver.maximize_window()\n",
    "url_login = \"https://eksisozluk.com/giris\"\n",
    "driver.uc_open_with_reconnect(url_login, 10)\n",
    "sleep(1)\n",
    "counter = 0\n",
    "for i in range(len(not_downloaded_for_selenium)):\n",
    "    counter += 1\n",
    "    if counter %100 == 0:\n",
    "        print('checkpoint at counter: ', counter); print('len(ok_images_selenium) : ', len(ok_images_selenium))\n",
    "    img_url = df['img_url'][i]\n",
    "    img_index = df['img_index'][i]\n",
    "    entry_id = df['entry_id'][i]\n",
    "    url_id = img_url.split('/')[-1].split('.')[0]\n",
    "    try:\n",
    "        driver.get(\"https://soz.lk/i/\" + url_id)\n",
    "        sleep(2)\n",
    "        image_element = driver.find_element(By.ID, \"image\")\n",
    "        image_src = image_element.get_attribute(\"src\")\n",
    "        response = requests.get(image_src, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            img_path = os.path.join(downloaded_images_selenium, f\"img_{img_index}.jpg\")\n",
    "            with open(img_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            filename = img_path.split(\"\\\\\")[-1]\n",
    "            ok_images_selenium.append(img_index)\n",
    "            df.at[i+1, \"path\"] = filename\n",
    "            df.at[i+1, \"response_status_code\"] = response.status_code\n",
    "        else:\n",
    "            not_ok_images_selenium.append(img_index)\n",
    "            df.at[i+1, \"response_status_code\"] = response.status_code\n",
    "    except Exception as e:\n",
    "        not_ok_images_selenium.append(img_index)\n",
    "\n",
    "print(\"Selenium has finished running.\")\n",
    "print('\\n-Result-')\n",
    "print('Lenght of Ok Images: ', len(ok_images_selenium))\n",
    "print('Lenght of Not Ok Images: ', len(not_ok_images_selenium))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb736cd2-5e81-4da4-802a-9207113d0ee3",
   "metadata": {},
   "source": [
    "# Clear XLSX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40d7852-1946-4b05-92d3-3693edad2c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Kept only rows with images.\n",
      "New file: 'C:\\Users\\soner.kar\\Desktop\\My Projects\\SözlükLens\\5_dataset_only_existing_37.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Match images in the folder with those in the xlsx file and remove unmatched rows from the xlsx\n",
    "\n",
    "# 1- Read all .jpg files in the folder\n",
    "all_files = os.listdir(downloaded_images)\n",
    "jpg_files = [f for f in all_files if f.endswith('.jpg')]\n",
    "\n",
    "# 2- Extract existing file numbers\n",
    "existing_numbers = set()\n",
    "for filename in jpg_files:\n",
    "    try:\n",
    "        number_part = int(filename.replace(\"img_\", \"\").replace(\".jpg\", \"\"))\n",
    "        existing_numbers.add(number_part)\n",
    "    except ValueError:\n",
    "        pass  # ignore if there's an error in the filename\n",
    "\n",
    "# 3- Read the Excel file\n",
    "df = pd.read_excel(final_file_path)\n",
    "\n",
    "# 4- Keep only rows with existing img_index values\n",
    "df_filtered = df[df['img_index'].isin(existing_numbers)]\n",
    "\n",
    "# 5- Save the new file\n",
    "from config import img_index ###---------------------------------------------------------------------------------------------###\n",
    "path_output = os.path.join(project_root, f\"5_dataset_only_existing_{img_index}.xlsx\")\n",
    "df_filtered.to_excel(path_output, index=False)\n",
    "\n",
    "print(f\"Done. Kept only rows with images.\\nNew file: '{path_output}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586bbb7c-6ee9-40a8-9454-e21e845fa12d",
   "metadata": {},
   "source": [
    "# Rename Images and Update XLSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc76f6d1-a151-4f20-baab-8a28ff54ff86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images and Excel data ('6_dataset_final.xlsx') updated with new order.\n"
     ]
    }
   ],
   "source": [
    "# Rename images and update the img_index column in the xlsx file accordingly\n",
    "\n",
    "# 1- Paths\n",
    "final_file_path = path_output\n",
    "\n",
    "# 2- Read all .jpg files\n",
    "jpg_files = [f for f in os.listdir(downloaded_images) if f.endswith('.jpg')]\n",
    "\n",
    "# 3- Extract numbers from file names\n",
    "img_numbers = []\n",
    "file_map = {}  # old filename -> number\n",
    "\n",
    "for file in jpg_files:\n",
    "    try:\n",
    "        number = int(file.replace('img_', '').replace('.jpg', ''))\n",
    "        img_numbers.append(number)\n",
    "        file_map[number] = file\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# 4- Sort image numbers\n",
    "img_numbers_sorted = sorted(img_numbers)\n",
    "\n",
    "# 5- Read the Excel file\n",
    "df = pd.read_excel(final_file_path)\n",
    "\n",
    "# 6- Select rows with img_index values matching images in the folder\n",
    "df_filtered = df[df['img_index'].isin(img_numbers_sorted)].copy()\n",
    "\n",
    "# 7- Create a new dataframe:\n",
    "# img_1.jpg → take the row with the old number, set img_index = 1\n",
    "new_rows = []\n",
    "\n",
    "for new_idx, old_number in enumerate(img_numbers_sorted, start=1):\n",
    "    row = df_filtered[df_filtered['img_index'] == old_number]\n",
    "    if not row.empty:\n",
    "        updated_row = row.copy()\n",
    "        updated_row.loc[:, 'img_index'] = new_idx  # only update img_index\n",
    "        new_rows.append(updated_row)\n",
    "\n",
    "# 8- Combine all new rows\n",
    "df_final = pd.concat(new_rows, ignore_index=True)\n",
    "\n",
    "# 9- Rename old files according to the new order\n",
    "for new_index, old_number in enumerate(img_numbers_sorted, start=1):\n",
    "    old_filename = file_map[old_number]\n",
    "    old_path = os.path.join(downloaded_images, old_filename)\n",
    "    new_filename = f\"img_{new_index}.jpg\"\n",
    "    new_path = os.path.join(downloaded_images, new_filename)\n",
    "    \n",
    "    if old_path != new_path:\n",
    "        os.rename(old_path, new_path)\n",
    "\n",
    "# 10- Save the updated Excel file\n",
    "output_final_file_path = os.path.join(project_root, \"6_dataset_final.xlsx\")\n",
    "df_final.to_excel(output_final_file_path, index=False)\n",
    "\n",
    "print(f\"Images and Excel data ('{os.path.basename(output_final_file_path)}') updated with new order.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
